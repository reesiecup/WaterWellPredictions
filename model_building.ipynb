{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Training Set Data\n",
    "Create a copy of training set feature data (named as `train_X`), and a copy of training set label data (named as `train_y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('training_set_values.csv')\n",
    "y = pd.read_csv('training_set_labels.csv')\n",
    "train_X = X.copy()\n",
    "train_y = y.copy().drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Pipeline\n",
    "The full pipeline contains the following components (in order):<br>\n",
    "- Select features that will be included in the model based on the results from exploratory data analysis\n",
    "- Clean `construction_year` by replace value '0' to missing data\n",
    "- Engineer `installer` by keeping top 10 most frequent values and replacing the rest to 'other'\n",
    "- Stardardize numerical features\n",
    "- Impute the most frequent value for missing data for categorical features\n",
    "- Apply One-hot coding to categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Select Features\n",
    "def select_features(data):\n",
    "    list_to_drop = ['id', 'date_recorded', 'funder', 'wpt_name', 'num_private', 'subvillage', 'region', 'region_code',\n",
    "                    'district_code', 'lga', 'ward', 'scheme_management', 'recorded_by', 'scheme_name', 'extraction_type', 'extraction_type_group', \n",
    "                    'payment', 'water_quality', 'quantity_group', 'source', 'waterpoint_type']\n",
    "    data = data.drop(list_to_drop, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Clean construction_year Feature\n",
    "def clean_year(data):\n",
    "    median_construction_year = data['construction_year'].median()\n",
    "    data = data.replace({'construction_year': {0: median_construction_year}}) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Engineer installer\n",
    "def engineer_installer(data):\n",
    "    data = data.replace({'installer': {'0': 'NaN'}}) \n",
    "    list_to_df = data['installer'].value_counts().reset_index()\n",
    "    df_to_list = list_to_df['index'].to_list()\n",
    "    df_to_list.remove('NaN')\n",
    "    for i in range(0, len(data['installer'])):\n",
    "        if data.iloc[i]['installer'] not in df_to_list[:10]:\n",
    "            data.loc[i:i, 'installer'] = 'Other'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Prepare train_X (i.e., full pipeline)\n",
    "def prepare_data(data):\n",
    "    data = engineer_installer(clean_year(select_features(data)))\n",
    "    data_num = data.select_dtypes(exclude = 'object')\n",
    "    num_pipeline = Pipeline([('std_scaler', StandardScaler()),])\n",
    "    data_cat = data.select_dtypes(include = 'object')\n",
    "    cat_pipeline = Pipeline([('imputer', SimpleImputer(missing_values = np.nan, strategy = \"most_frequent\")),\n",
    "                             ('ohe', OneHotEncoder()),])\n",
    "    num_attribs = list(data_num) \n",
    "    cat_attribs = list(data_cat)\n",
    "    full_pipeline = ColumnTransformer([(\"num\", num_pipeline, num_attribs), \n",
    "                                       (\"cat\", cat_pipeline, cat_attribs),]) \n",
    "    data_prepared = full_pipeline.fit_transform(data)\n",
    "    return data_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare `train_X` by using full pipeline, and prepare `train_y` by applying `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "train_X = prepare_data(train_X)\n",
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Train a few dirty and quick model with standard parameter, and based on its results to decide which model should be fine tuned and used. Six classifiers are trained and cross validated using function `cross_val`. Each model's average accurary score and its standard deviation are printed using function `display_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(classifier, X, y):\n",
    "    clf = classifier\n",
    "    clf.fit(X, y)\n",
    "    clf_scores = cross_val_score(clf, X, y, cv = 10, n_jobs = -1)\n",
    "    avg_accuracy = clf_scores.mean()\n",
    "    std_accuracy = clf_scores.std()\n",
    "    return avg_accuracy, std_accuracy\n",
    "\n",
    "def display_scores(classifier_name, avg_accuracy, std_accuracy):\n",
    "    print(classifier_name)\n",
    "    print('Mean: ', avg_accuracy)\n",
    "    print('Standard Deviation: ', std_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Support Vector Classification\n",
      "Mean:  0.7303032296036772\n",
      "Standard Deviation:  0.005327665724590623\n",
      "Linear classifiers with SGD training\n",
      "Mean:  0.724748167060541\n",
      "Standard Deviation:  0.006365990081275285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes\n",
      "Mean:  0.3025254793896805\n",
      "Standard Deviation:  0.014991231967817192\n",
      "Naive Bayes classifier for multivariate Bernoulli models\n",
      "Mean:  0.6589565905558069\n",
      "Standard Deviation:  0.005561560049406029\n",
      "Decision Tree Classifier\n",
      "Mean:  0.7545449289397614\n",
      "Standard Deviation:  0.005620641720731255\n",
      "Random Forest Classifier\n",
      "Mean:  0.6899162214570166\n",
      "Standard Deviation:  0.00519800956212946\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy, std_accuracy = cross_val(LinearSVC(random_state = 42, tol = 1e-5, dual = False), train_X, train_y)\n",
    "display_scores('Linear Support Vector Classification', avg_accuracy, std_accuracy)\n",
    "\n",
    "avg_accuracy, std_accuracy = cross_val(linear_model.SGDClassifier(max_iter=1000, tol=1e-3, n_jobs = -1, random_state = 42), train_X, train_y)\n",
    "display_scores('Linear classifiers with SGD training', avg_accuracy, std_accuracy)\n",
    "\n",
    "avg_accuracy, std_accuracy = cross_val(GaussianNB(), train_X.toarray(), train_y)\n",
    "display_scores('Gaussian Naive Bayes', avg_accuracy, std_accuracy)\n",
    "\n",
    "avg_accuracy, std_accuracy = cross_val(BernoulliNB(), train_X.toarray(), train_y)\n",
    "display_scores('Naive Bayes classifier for multivariate Bernoulli models', avg_accuracy, std_accuracy)\n",
    "\n",
    "avg_accuracy, std_accuracy = cross_val(DecisionTreeClassifier(random_state = 42), train_X, train_y)\n",
    "display_scores('Decision Tree Classifier', avg_accuracy, std_accuracy)\n",
    "\n",
    "avg_accuracy, std_accuracy = cross_val(RandomForestClassifier(n_estimators = 100, max_depth = 2, random_state = 42), train_X, train_y)\n",
    "display_scores('Random Forest Classifier', avg_accuracy, std_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, Decision Tree Classifier should be further fine tuned. Random Forest Classifier usually performs better than Decisision Tree Classifier (although it is not the case here), thus Random Forest Classifier will be fine tuned as well.<br>\n",
    "\n",
    "Using `grid_search` to fine tune the classifiers mentioned above. For Decision Tree Classifier, `min_sample_split` is adjusted to regulate the classifier, and `max_features` is adjusted to check whether the number of features used in the classifier is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:  {'max_features': 'log2', 'min_samples_split': 10}\n",
      "Best Estimator: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n",
      "Best Score:  0.7601515151515151\n"
     ]
    }
   ],
   "source": [
    "param_grid_tree = [{'min_samples_split': [6, 8, 10], 'max_features': ['auto', 'log2', 'sqrt']},] \n",
    "tree = DecisionTreeClassifier(random_state = 42) \n",
    "grid_search_tree = GridSearchCV(tree, param_grid_tree, cv = 5, \n",
    "                                scoring = 'accuracy', return_train_score = True) \n",
    "grid_search_tree.fit(train_X, train_y)\n",
    "print('Best Parameter: ', grid_search_tree.best_params_)\n",
    "print('Best Estimator:', grid_search_tree.best_estimator_)\n",
    "print('Best Score: ', grid_search_tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Random Forest Classifier, `n_estimators` is adjusted to determine what number of the trees in the model renders the best accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter:  {'n_estimators': 300}\n",
      "Best Estimator: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Best Score:  0.7994781144781145\n"
     ]
    }
   ],
   "source": [
    "param_grid_forest = [{'n_estimators': [10, 100, 300]}, {'max_features': ['auto']},] \n",
    "forest = RandomForestClassifier(random_state = 42) \n",
    "grid_search_forest = GridSearchCV(forest, param_grid_forest, cv = 5, \n",
    "                                  scoring = 'accuracy', return_train_score = True) \n",
    "grid_search_forest.fit(train_X, train_y)\n",
    "print('Best Parameter: ', grid_search_forest.best_params_)\n",
    "print('Best Estimator:', grid_search_forest.best_estimator_)\n",
    "print('Best Score: ', grid_search_forest.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, Random Forest classifier out performs Decision Tree Classifier. Save the fine tuned Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveClassifier = open(\"RandomForest.pickle\",\"wb\")\n",
    "pickle.dump(grid_search_forest.best_estimator_, SaveClassifier)\n",
    "SaveClassifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "Use the fine tuned Random Forest Classifier to predict the label for test set (i.e., the functionality of the water well based on information provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/reesetou/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "final_model = grid_search_forest.best_estimator_\n",
    "test_X = pd.read_csv('testing_set_values.csv')\n",
    "test_X = prepare_data(test_X)\n",
    "final_predictions = final_model.predict(test_X) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction to the `SubmissionFilled.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = le.inverse_transform(final_predictions)\n",
    "test_y = pd.read_csv('Submission.csv')\n",
    "test_y['status_group'] = final_predictions\n",
    "test_y.to_csv('SubmissionFilled.csv' ,index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scored accuracy rate 79.57% on test set according to the competition site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37]",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
